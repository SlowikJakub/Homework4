{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMH2z6Pmba22jYYQsc5Vftr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SlowikJakub/Homework4/blob/main/Problem2PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vabSN9_QkQCg"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import collections\n",
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6x8QP2k-9W",
        "outputId": "e2dcb7cb-3f99-4c37-b159-222eb07984df"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-mvb1I6lBaP"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhKEGVPXlSa-",
        "outputId": "8fe0ad1d-16df-474d-c5fa-825d127ac028"
      },
      "source": [
        "import torch.nn as nn\n",
        "img, _ = cifar10[0]\n",
        "pool=nn.MaxPool2d(2)\n",
        "output=pool(img.unsqueeze(0))\n",
        "img.unsqueeze(0).shape , output.shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPL4UbidrogO"
      },
      "source": [
        "model= nn.Sequential(\n",
        "    nn.Conv2d(3,16, kernel_size=3, padding=1),\n",
        "    nn.Tanh(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(3,16, kernel_size=3, padding=1),\n",
        "    nn.Tanh(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Linear(8*8*8,32),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(32,4)\n",
        ")"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC115hfamAGQ"
      },
      "source": [
        "import torch.nn as nn\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(3,16, kernel_size=3, padding=1)\n",
        "    self.act1=nn.Tanh()\n",
        "    self.pool1=nn.MaxPool2d(2)\n",
        "    self.conv2=nn.Conv2d(16,8, kernel_size=3, padding=1)\n",
        "    self.act2=nn.Tanh()\n",
        "    self.pool2=nn.MaxPool2d(2)\n",
        "    self.fc1=nn.Linear(8*8*8,32)\n",
        "    self.act3=nn.Tanh()\n",
        "    self.fc2=nn.Linear(32,10)\n",
        "  \n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.pool1(self.act1(self.conv1(x)))\n",
        "    out = self.pool2(self.act2(self.conv2(out)))\n",
        "    out = out.view(-1, 8*8*8)\n",
        "    out = self.act3(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1BS5zNUwbVQ",
        "outputId": "65e12583-2f3e-447f-d7b8-aecbcd7e893e"
      },
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hW-UpwGoFQj"
      },
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        \n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA_hURzEqGjp",
        "outputId": "f92cf018-1fbb-4a14-c3aa-2783fd6a2153"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle =True)\n",
        "\n",
        "model= Net().to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(),lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs=200,\n",
        "    optimizer =optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader=train_loader\n",
        ")"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-22 23:26:11.260458 Epoch 1, Training loss 2.0220583553814215\n",
            "2021-04-22 23:27:32.966416 Epoch 10, Training loss 1.1681738493540097\n",
            "2021-04-22 23:29:03.835152 Epoch 20, Training loss 1.0094560681249174\n",
            "2021-04-22 23:30:35.099368 Epoch 30, Training loss 0.9095829546908893\n",
            "2021-04-22 23:32:06.563801 Epoch 40, Training loss 0.8482539858811956\n",
            "2021-04-22 23:33:39.364274 Epoch 50, Training loss 0.8062313833962316\n",
            "2021-04-22 23:35:11.685619 Epoch 60, Training loss 0.7736978185603686\n",
            "2021-04-22 23:36:43.361465 Epoch 70, Training loss 0.7462159613971515\n",
            "2021-04-22 23:38:18.455970 Epoch 80, Training loss 0.723585478789971\n",
            "2021-04-22 23:39:53.642589 Epoch 90, Training loss 0.706111645264089\n",
            "2021-04-22 23:41:25.857447 Epoch 100, Training loss 0.6876289860138198\n",
            "2021-04-22 23:42:57.326929 Epoch 110, Training loss 0.6724071498874509\n",
            "2021-04-22 23:44:29.503413 Epoch 120, Training loss 0.6572949317715052\n",
            "2021-04-22 23:46:01.728421 Epoch 130, Training loss 0.6437669681466144\n",
            "2021-04-22 23:47:34.244172 Epoch 140, Training loss 0.633761653700448\n",
            "2021-04-22 23:49:08.445450 Epoch 150, Training loss 0.6196415853088774\n",
            "2021-04-22 23:50:42.219299 Epoch 160, Training loss 0.6098788567363759\n",
            "2021-04-22 23:52:15.564419 Epoch 170, Training loss 0.6022057454756764\n",
            "2021-04-22 23:53:49.095200 Epoch 180, Training loss 0.5915747567287186\n",
            "2021-04-22 23:55:23.441132 Epoch 190, Training loss 0.5835901589497275\n",
            "2021-04-22 23:56:58.425602 Epoch 200, Training loss 0.5775151021416535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TklkBzzNxStH",
        "outputId": "c92a8c0b-555c-4ae8-8dd7-3bffa4cd5e79"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    accdict = {}\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        accdict[name] = correct / total\n",
        "    return accdict\n",
        "\n",
        "validate(model, train_loader, val_loader)\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.79\n",
            "Accuracy val: 0.64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 0.79458, 'val': 0.6377}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    }
  ]
}